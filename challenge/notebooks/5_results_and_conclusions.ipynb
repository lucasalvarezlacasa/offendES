{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **Redes Neuronales para PLN - Pr√°ctica Final**\n",
    "## Notebook 5 - Resumen de Resultados y Conclusiones\n",
    "### Alumno: Alvarez Lacasa, Lucas Alfredo\n",
    "\n",
    "El objetivo de esta √∫ltima notebook es el de reunir los resultados de cada una de las pruebas anteriores y mencionar algunas conclusiones, puntos de mejora y/o exploraci√≥n de cada al futuro."
   ],
   "id": "7760845fe20bc7ae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Imports globales\n",
    "\n",
    "Los imports son declarados en esta primera secci√≥n de la notebook"
   ],
   "id": "af336305276ba246"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:01:42.782793Z",
     "start_time": "2024-06-15T22:01:42.780550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "from dataclasses import dataclass"
   ],
   "id": "28a9f3a01bd1f47",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Funciones y clases auxiliares\n",
    "\n",
    "Definir√© un conjunto de funciones y clases utilitarias para evitar duplicaci√≥n de c√≥digo, haciendo que la notebook sea m√°s mantenible y sencilla de volver a ejecutar. Creo que en general se trata de una buena pr√°ctica sobre todo en notebooks largas para poder aislar ejecuci√≥n de c√≥digo de forma de que sea menos probable cometer errores.\n",
    "\n",
    "La gran mayor√≠a de funciones y clases utilitarias (sin importar para qu√© secci√≥n del √≠ndice correspondan) ser√°n listadas aqu√≠ por una cuesti√≥n de simplicidad y de poder re-cargar la notebook m√°s f√°cilmente mientras desarrollo."
   ],
   "id": "47a92e94bdc333b7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:01:43.734279Z",
     "start_time": "2024-06-15T22:01:43.716368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "=========================\n",
    "Route resolution class\n",
    "\n",
    "EDIT THIS CLASS depending on where you will be running this notebook!\n",
    "=========================\n",
    "\"\"\"\n",
    "\n",
    "COLAB_BASE_MOUNT_POINT: str = \"/content/drive\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RouteConfig:\n",
    "    notebook_name: str\n",
    "    run_in_colab: bool = False\n",
    "    # TODO: Change this to your base Colab path!!! =========>\n",
    "    colab_base_mount_point: str = COLAB_BASE_MOUNT_POINT\n",
    "    colab_practice_base_dir: str = f\"{COLAB_BASE_MOUNT_POINT}/My Drive/UNED/master_nlp/RedesNeuronalesNLP/Practica_Final/challenge\"\n",
    "    local_practice_base_dir: str = \"/home/lucas/Desktop/Personal/master_nlp/RedesNeuronalesNLP/Practica_Final/challenge\"\n",
    "    # ======================================================>\n",
    "    dataset_rel_folder_path: str = os.path.join(\"data\", \"dataset\", \"OffendES\")\n",
    "    dataset_train_file_name: str = \"train.csv\"\n",
    "    dataset_test_file_name: str = \"test.csv\"\n",
    "    exp_output_rel_folder_path: str = \"experiment_output\"\n",
    "\n",
    "\n",
    "class RouteResolver:\n",
    "    \"\"\" This object abstracts the retrieval of the files used in this notebook by only editing the RouteConfig class received \"\"\"\n",
    "\n",
    "    def __init__(self, route_config: RouteConfig) -> None:\n",
    "        if route_config.run_in_colab:\n",
    "            # Import and mount into the base mount path for Google Colab\n",
    "            from google.colab import drive\n",
    "            drive.mount(route_config.colab_base_mount_point)\n",
    "\n",
    "        self._config: RouteConfig = route_config\n",
    "\n",
    "        # Create experiment output folder for this notebook\n",
    "        exp_output_notebook_folder: str = self.current_exp_output_folder()\n",
    "        if not os.path.isdir(exp_output_notebook_folder):\n",
    "            print(f\"Experiment output folder for this notebook does not exist. Creating...\")\n",
    "            os.mkdir(exp_output_notebook_folder)\n",
    "\n",
    "    def base_folder_path(self) -> str:\n",
    "        \"\"\"Returns the base path depending if you're running in Colab or not\"\"\"\n",
    "        return self._config.colab_practice_base_dir if self._config.run_in_colab else self._config.local_practice_base_dir\n",
    "\n",
    "    def get_datasets_folder(self) -> str:\n",
    "        \"\"\"Returns the dataset folder\"\"\"\n",
    "        return os.path.join(self.base_folder_path(), self._config.dataset_rel_folder_path)\n",
    "\n",
    "    def get_training_dataset_path(self) -> str:\n",
    "        \"\"\"Returns path to the original training dataset file.\"\"\"\n",
    "        return os.path.join(self.get_datasets_folder(), self._config.dataset_train_file_name)\n",
    "\n",
    "    def get_testing_dataset_path(self) -> str:\n",
    "        \"\"\"Returns path to the original test dataset file.\"\"\"\n",
    "        return os.path.join(self.get_datasets_folder(), self._config.dataset_test_file_name)\n",
    "\n",
    "    def get_exp_output_folder(self) -> str:\n",
    "        \"\"\"Returns the path to the experiment outputs folder\"\"\"\n",
    "        return os.path.join(self.base_folder_path(), self._config.exp_output_rel_folder_path)\n",
    "\n",
    "    def get_exp_output_notebook_folder(self, flow_number: int) -> str:\n",
    "        \"\"\"Given flow number if returns the experiment output folder for it\"\"\"\n",
    "        notebook_name: str = f\"PracticaFinal_AlvarezLacasaLucas_{str(flow_number)}\"\n",
    "        exp_output_notebook_folder: str = os.path.join(self.get_exp_output_folder(), notebook_name)\n",
    "        validate_condition(condition=os.path.isdir(exp_output_notebook_folder),\n",
    "                           msg=f\"Can't find experiment output for flow: {notebook_name}\")\n",
    "        return exp_output_notebook_folder\n",
    "\n",
    "    def current_exp_output_folder(self) -> str:\n",
    "        \"\"\"Returns experiment output folder for current notebook being ran\"\"\"\n",
    "        return os.path.join(self.get_exp_output_folder(), self._config.notebook_name)\n",
    "\n",
    "    def dump_registered_paths(self) -> None:\n",
    "        running_env: str = \"COLAB\" if self._config.run_in_colab else \"LOCAL\"\n",
    "        print(\"Registered application paths ========\")\n",
    "        print(f\"Running environment: {running_env}\")\n",
    "        print(f\"Experiment output for this notebook is located in: {self.current_exp_output_folder()}\")\n",
    "        print(f\"Original Training dataset file is located in: {self.get_training_dataset_path()}\")\n",
    "        print(f\"Original Test dataset file is located in: {self.get_testing_dataset_path()}\")"
   ],
   "id": "d547506cba560614",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:01:44.456567Z",
     "start_time": "2024-06-15T22:01:44.450583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "=========================================\n",
    "General utility functions\n",
    "=========================================\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def validate_condition(condition: bool, msg: str, exc_type: type[Exception] = ValueError) -> None:\n",
    "    \"\"\"\n",
    "    If condition is not met, it will raise a ValueError with the arguments provided\n",
    "    :param condition: condition to validate\n",
    "    :param msg: string to display in the error\n",
    "    :param exc_type: type of exception we want to raise. ValueError by default\n",
    "    :return: ValueError in case condition is not met, None otherwise\n",
    "    \"\"\"\n",
    "    if not condition:\n",
    "        raise exc_type(msg)\n",
    "\n",
    "\n",
    "def create_dir_if_not_exists(folder: str) -> None:\n",
    "    # Create a directory if it does not exist already\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)"
   ],
   "id": "8bd75e4fb5264aa8",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Resoluci√≥n de rutas\n",
    "\n",
    "Utilizaremos una clase `RouteResolver` para resolver las rutas, de forma de aislar esa informaci√≥n all√≠ y poder modificarla en un √∫nico punto del notebook.\n",
    "\n",
    "Verificar el output de la siguiente celda en caso de querer re-ejecutar la notebook para asegurarse de que las rutas apuntan al lugar correcto. Esta vez utilic√© `run_in_colab=False` ya que todo el procesamiento pude hacerlo en mi portatil personal."
   ],
   "id": "d988ae1c7fb7321f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T22:01:49.458081Z",
     "start_time": "2024-06-15T22:01:49.455541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Routes\n",
    "route_resolver: RouteResolver = RouteResolver(\n",
    "    RouteConfig(run_in_colab=False, notebook_name=\"5_results_and_conclusions\"))\n",
    "route_resolver.dump_registered_paths()"
   ],
   "id": "aceea5b8f2208505",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment output folder for this notebook does not exist. Creating...\n",
      "Registered application paths ========\n",
      "Running environment: LOCAL\n",
      "Experiment output for this notebook is located in: /home/lucas/Desktop/Personal/master_nlp/RedesNeuronalesNLP/Practica_Final/challenge/experiment_output/PracticaFinal_AlvarezLacasaLucas_5\n",
      "Original Training dataset file is located in: /home/lucas/Desktop/Personal/master_nlp/RedesNeuronalesNLP/Practica_Final/challenge/data/dataset/OffendES/train.csv\n",
      "Original Test dataset file is located in: /home/lucas/Desktop/Personal/master_nlp/RedesNeuronalesNLP/Practica_Final/challenge/data/dataset/OffendES/test.csv\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Resultados\n",
    "\n",
    "El resumen de los mejores resultados de todas las notebooks anteriores se presenta en la siguiente tabla. _Notar que `MC` significa `MULTI-CLASS` y `BC` hace referencia a la performance para `BINARY-CLASS`_.. \n",
    "\n",
    "Para resolver este problema siempre se entrenaron los modelos sobre las 4 labels brindadas (`OFP`, `OFG`, `NO`, `NOM`). Para evaluar su desempe√±o y detectar `hate` o `no_hate`, las predicciones multi-class fueron mapeadas a su correspondiente binario siguiendo las reglas definidas en el enunciado.\n",
    "En caso de haber entrenado algunos modelos √∫nicamente usando las labels binarias, se podr√≠a quiz√°s haber llegado a resultados superadores, puesto que la tarea que el clasificador tiene que resolver en ese caso ser√≠a mucho m√°s sencilla que distinguir sobre las 4 labels como se est√° haciendo. Esto es un punto que podr√≠amos considerar como de mejora.\n",
    "\n",
    "| Notebook | Model                                                                                                                                      | Model Size | Dataset  | Representation                                                                    | macro-prec (MC) | macro-rec (MC) | macro-F1 (MC) | macro-prec (BC) | macro-rec (BC) | macro-F1 (BC) | Config highlights                                                                                                                                                                                                                                                                                                                                                                                     |\n",
    "| -------- | ------------------------------------------------------------------------------------------------------------------------------------------ | ---------- | -------- | --------------------------------------------------------------------------------- |-----------------|-------------------|---------------|----------------------|-------------------|---------------| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| 2        | Naive Bayes                                                                                                                                |            | v2       | BOW: tf-idf<br>Level: word<br>N-grams: (1.3)                                      | 0.6000          | 0.5700            | 0.5706        | 0.7900               | 0.7500            | 0.7693        | \\-                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| 2        | LogisticRegression                                                                                                                         |            | v2       | BOW: tf-idf<br>Level: word<br>N-grams: (1.2)                                      | 0.6242          | 0.6001            | 0.6113        | 0.8045               | 0.7739            | 0.7880        | (C=10, class_weight='balanced', max_iter=500)                                                                                                                                                                                                                                                                                                                                                         |\n",
    "| 2        | SVM                                                                                                                                        |            | v2       | BOW: tf-idf<br>Level: word<br>N-grams: (1.2)                                      | 0.6261          | 0.5951            | 0.6065        | 0.8149               | 0.7739            | 0.7923        | (C=1, class_weight='balanced', gamma=1, kernel='linear')                                                                                                                                                                                                                                                                                                                                              |\n",
    "| 2        | RandomForests                                                                                                                              |            | v2       | BOW: tf-idf<br>Level: word<br>N-grams: (1.3)<br>Method: chi2 - 10k                | 0.5662          | 0.5229            | 0.5369        | 0.8153               | 0.6952            | 0.7350        | \\-                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
    "| 2        | XGBoost                                                                                                                                    |            | v2       | BOW: tf-idf<br>Level: word<br>N-grams: (1.3)<br>Method: chi2 - 10k                | 0.5915          | 0.5579            | 0.5639        | 0.7961               | 0.7342            | 0.7597        | (learning_rate=0.1, max_depth=16, n_estimators=512)                                                                                                                                                                                                                                                                                                                                                   |\n",
    "|          |                                                                                                                                            |            |          |                                                                                   |                 |                   |               |                      |                   |               |                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| 3        | Dense NNs                                                                                                                                  | 4.27M      | v2       | Embeddings: from scratch<br>max_length=128<br>vocab_size=10001<br>output_dim: 100 | 0.6010          | 0.5275            | 0.5566        | 0.7871               | 0.7116            | 0.7407        | (batch_size=32, dense_dims=[256, 4], dense_act=[\"relu\", \"softmax\"], dp_after_emb=0.5, dp_before_class_head=0.7, class_weight=None, Adam(learning_rate=0.001), EarlyStopping(monitor='val_loss', mode='min', patience=2, min_delta=0.01))                                                                                                                                                              |\n",
    "| 3        | CNNs                                                                                                                                       | 1.2M       | v6       | Embeddings: from scratch<br>max_length=128<br>vocab_size=10001<br>output_dim: 100 | 0.5685          | 0.5548            | 0.5611        | 0.7238               | 0.7061            | 0.7144        | (batch_size=32, cnn_filter_dims: [64], cnn_kernel_sizes=[3], cnn_activations=[\"relu\"], dense_act=[\"relu\"], use_global_pooling=False, dp_after_emb=0.5, dp_after_pooling=[0.0], dp_before_class_head=0.1, dense_dims=[64, 4], dense_act=[\"relu\", \"softmax\"], class_weight=None, Adam(learning_rate=0.001), EarlyStopping(monitor='val_loss', mode='min', patience=2, min_delta=0.01))                  |\n",
    "| 3        | RNNs                                                                                                                                       | 1M         | v6       | Embeddings: from scratch<br>max_length=128<br>vocab_size=10001<br>output_dim: 100 | 0.6096          | 0.5736            | 0.5900        | 0.7761               | 0.7462            | 0.7598        | (batch_size=32, emb_dp=0.5, types=[RNNName.LSTM.value]\\*2, units=[64, 32], bidirectional=True, unroll=True, internal_dp_rates=[0.0]\\*2, recurrent_dp_rates=[0.1]\\*2, external_dp_rates=[0.3]\\*2, dense_dims=[128, 4], dense_dp=[0.3, 0.0], dense_act=[\"relu\", \"softmax\"], class_weight=None, RMSprop(learning_rate=0.001), EarlyStopping(monitor='val_loss', mode='min', patience=2, min_delta=0.01)) |\n",
    "|          |                                                                                                                                            |            |          |                                                                                   |                 |                   |               |                      |                   |               |                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| 4        | [GPT 3.5 turbo](https://openai.com/blog/chatgpt) Zero Shot                                                                                 | 175B       | original | Tokenizer<br>Vocab: ~50k tokens<br>Max Input: 4096 tokens                         | 0.3811          | 0.5195            | 0.3560        | 0.6322               | 0.7451            | 0.7816        |                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| 4        | [GPT-4](https://openai.com/research/gpt-4) Zero Shot                                                                                       | 1.75T      | v4       | Tokenizer<br>Vocab: ~100k tokens<br>Max Input: 8192 tokens                        | 0.4857          | 0.6398            | 0.5255        | 0.7099               | 0.8532            | 0.7419        |                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| 4        | [mDeBERTa-v3-base-xnli-multilingual-nli-2mil7](https://huggingface.co/MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7) Zero Shot | 279M       | v4       | Tokenizer<br>Vocab: ~ 30522 tokens<br>Max Input: 512 tokens                       | 0.3261          | 0.3511            | 0.2500        | 0.6355               | 0.7218            | 0.6522        |                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| 4        | [robertuito-hate-speech](https://huggingface.co/pysentimiento/robertuito-hate-speech)                                                      | ~114M      | v4       | Tokenizer<br>Vocab: ~ 30k tokens<br>Max Input: 512 tokens                         | \\-              | \\-                | \\-            | 0.6858               | 0.6584            | 0.6702        |                                                                                                                                                                                                                                                                                                                                                                                                       |\n",
    "| 4        | [paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) Setfit         | 118M       | v7       | Tokenizer<br>Vocab: ~ 250k tokens<br>Max Input: 128 tokens                        | 0.6361          | 0.6321            | 0.6339        | 0.7887               | 0.7795            | 0.7840        | (batch_size=16, num_iterations=3, num_epochs=1, add_early_stopping=False, early_stopping_patience=0)                                                                                                                                                                                                                                                                                                  |\n",
    "| 4        | [distiluse-base-multilingual-cased-v1](https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v1) Setfit           | 135M       | v7       | Tokenizer<br>Vocab: ~ 120k tokens<br>Max Input: 128 tokens                        | 0.6251          | 0.6130            | 0.6189        | 0.8008               | 0.7901            | 0.7953        | (batch_size=16, num_iterations=2, num_epochs=1, add_early_stopping=False, early_stopping_patience=0)                                                                                                                                                                                                                                                                                                  |\n",
    "| 4        | [LaBSE](https://huggingface.co/sentence-transformers/LaBSE) Setfit                                                                         | 471M       | v7       | Tokenizer<br>Vocab: ~ 501k tokens<br>Max Input: 256 tokens                        | 0.6941          | 0.6179            | **0.6495**    | 0.8257               | 0.7782            | **0.7992**    | (batch_size=16, num_iterations=2, num_epochs=3, add_early_stopping=False, early_stopping_patience=0)                                                                                                                                                                                                                                                                                                  |\n",
    "\n",
    "_Para una mejor visualizaci√≥n, todos los resultados pueden visualizarse tambi√©n en el siguiente [Google Spreadsheet](https://docs.google.com/spreadsheets/d/1mzY6YMFSP3kXgH3qgbJnX1w0f463ZQ06n32tLGgqOos/edit?usp=sharing)._\n",
    "\n"
   ],
   "id": "7acb6a045fb277be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusiones\n",
    "\n",
    "Las conclusiones presentadas en este caso ser√°n m√°s generales y abarcativas. La idea es brindar una imagen completa de lo que se prob√≥ y lo que no y comparar un poco la performance obtenida entre las distintas familias de modelos. Para las conclusiones m√°s espec√≠ficas de cada notebook, pueden ser encontradas al final de cada una de ellas.\n",
    "\n",
    "**Highlights**:\n",
    "- Se comenz√≥ planteando una serie de baselines a trav√©s de modelos ligeros de Machine Learning. Inmediatamente el an√°lisis de los datos sirvi√≥ para darnos cuenta del desbalance claro entre distintas clases. Se trabaj√≥ extensivamente con varias t√©cnicas para mitigar este problema, incluyendo: Random Over Sampling, creaci√≥n de ejemplos sint√©ticos con ChatGPT para la clase `OFG` y el uso de `class_weight=\"balanced\"` en muchos modelos para poder modificar el peso que cada sample tiene en la funci√≥n de p√©rdida en funci√≥n de la clase a la que pertenece. En mayor o menor medida, todas estas t√©cnicas contribuyeron notablemente a poder mejorar los resultados, ya que en las primeras pruebas eran realmente muy malos.\n",
    "- Para la evaluaci√≥n, se opta por reportar macro-averages, justamente porque el desbalance que hay entre la cantidad de samples de cada clase. De esta manera, al tener 4 labels, cada una de ellas aporta un 25% a los resultados. Este esquema es el recomendado para utilizar cuando se tienen grandes desbalances. Caso contrario, podr√≠amos tener la sensaci√≥n que el clasificador funciona muy bien si s√≥lo predijera `NO`, cuando este no ser√≠a el caso.\n",
    "- Se presentaron 8 versiones del dataset original, cada una con t√©cnicas diferentes. Sin embargo, la cantidad de cleanups realizados fue baja. Tambi√©n se implement√≥ una pipeline bastante gen√©rica para poder reproducir este proceso de forma sencilla y confiable. Para modelos contextuales, se intento eliminar la informaci√≥n que realmente estuvi√©ramos seguros de que podr√≠a introducir ruido, y se opt√≥ por dejar el resto para que se considere al momento de hacer el entrenamiento y la predicci√≥n. Esto sin duda fue un acierto.\n",
    "- ü•á **LaBSE SetFit**, con 64.95% de macro-f1 para MULTI-CLASS y 79.92% de macro-f1 BINARY-CLASS es el mejor modelo overall. Creo que esto era de esperarse, hablamos de un modelo de 471M de par√°metros pre-entrenado en 109 idiomas y que luego fine-tuneamos para nuestra tarea en concreto. Tengo experiencia poniendo este modelo en concreto en producci√≥n y si bien no es extremadamente liviano, puede ejecutarse en CPU y lograr unas 5 inferencias por segundo aproximadamente.\n",
    "- ü•à Menci√≥n especial para `LogisticRegression`, que nos permite alcanzar un 61.13% de macro-f1 para MULTI-CLASS y 78.80% de macro-f1 para BINARY-CLASS. Probablemente par√°metro-por-par√°metro el mejor modelo de todos los que pudimos entrenar.\n",
    "- ü•â Un poco decepcionado por los modelos de Deep Learning que entrenamos (DNNs, CNNs y RNNs), los cuales tuvieron una performance muy parecida a los planteados como baseline basados en algoritmos de Machine Learning ligeros. Hubiese esperado poder alcanzar una mucha mejor performance con ellos (obviamente no tan buena como la que alcanzan los contextuales).\n",
    "- A diferencia de la pr√°ctica anterior, la performance zero-shot de ChatGPT o GPT-4 es bastante pobre. Probablemente esto se deba a la dificultad de la tarea en este caso, a anotaciones que pueden ser un poco noisy y tambi√©n al hecho de que est√°n en espa√±ol y utilizan un vocabulario muy particular.\n",
    "\n",
    "_Para resumir, no me encuentro muy conforme con los resultados que alcanc√©. Siento que m√°s all√° de haber explorado todas las distintas arquitecturas y de haber gastado bastante tiempo itnentando mejorar los datos, siempre me encontr√© hiteando un ceiling que nunca pude sobrepasar. No estoy seguro si se debe a que hay anotaciones ruidosas (o inclusive que est√°n mal) o a qu√©, pero es un aspecto interesante para seguir analizando. Me encantar√≠a conocer cu√°l es la performance \"state-of-the-art\" esperada o alcanzada para este dataset._\n",
    "\n",
    "\n",
    "**Trabajo futuro**:\n",
    "- En cuanto a t√©cnicas para combatir el desbalance del dataset, under-sampling no fue explorada. Se prioriz√≥ intentar mantener la mayor cantidad de informaci√≥n posible.\n",
    "- Para modelos basados en Deep Learning (DNNs, CNNs, RNNs), no se exploraron representaciones de texto m√°s simples, como BOW (TF, TF-IDF) ni selecci√≥n de caracter√≠sticas sobre estas t√©cnicas. Se prioriz√≥ ir directamente con un esquema mucho m√°s cl√°sico y eficiente basado en el uso de `Tokenizer` y `Embedding layer`.\n",
    "- Se hicieron varios intentos por mejorar la performance obtenida a trav√©s de los datos. Sin embargo, fue com√∫n el caso para casi todos los modelos de tener un total de 20 elementos que sol√≠an predecirse como `NO` por nuestros modelos pero que estaban anotados como `OFG`. ¬øQuien falla en esos casos? Deber√≠amos haber revisado a mano esos ejemplos para intentar descubrir si se trata de un error de anotaci√≥n o si realmente los modelos est√°n fallando y por qu√©. Haber mejorado s√≥lo en esos pocos ejemplos nos hubiese permitido alcanzar una performance mucho m√°s alta.\n",
    "- No se hizo demasiada exploraci√≥n sobre los optimizadores. Sacando el caso de las `RNNs` (donde se prob√≥ con `RMSprop`), siempre se us√≥ Adam puesto que es un est√°ndar en las pruebas."
   ],
   "id": "c600f856ca4f91c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
